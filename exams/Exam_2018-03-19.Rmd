---
title: "Exam 2018-03-19"
author: "Maximilian Pfundstein"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    number_sections: true
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
set.seed(42)

```

# Assignment 1

## Question 1.1 (2 points)

For $\alpha = 2$ we define $M \geq \frac{f(x)}{g(x)} = \frac{\beta^2}{\lambda}\frac{x}{e^{x(\beta-\lambda)}}$.

Using the hint and recognizing $\gamma = \beta - \lambda$ we have two cases.

**Case 1:** $\gamma < 1$, then $\underset{x}{\text{max}} \frac{x}{e^(\gamma x)} \Rightarrow \infty$. So $M$ would be infinity which is not feasible.

**Case 2:** $\gamma \geq 1$, then $\gamma = \beta - \lambda = 1 \Rightarrow \lambda = \beta - 1$.

So $M = \frac{\beta^2}{\lambda} = \frac{\beta^2}{\beta -1}$ and with $\beta = 2$ we get $M = 4$.

## Question 1.2 (5 points)

The following function implements the Acceptance-Rejection-Sampling.

```{r}

################################################################################
# Assignment 1.2
################################################################################

acceptance_rejection_sampling = function(n, alpha = 2, beta = 2) {

  M = (beta^2)/(beta -1)
  lambda = beta - 1
  
  rs = c()
  rs_rejected = c()
  
  while (length(rs) < n) {
    # Take a random sample from our proposal (x-axis)
    z = rexp(n = 1, rate = lambda)
    
    # Take a uniform, thus a random y value
    u = runif(n = 1, min = 0, max = M * dexp(z, lambda))
    
    # Check in which region this on lies
    if (u <= dgamma(z, shape = alpha, rate = beta)) {
      rs = c(rs, z)
    }
    
    else {
      rs_rejected = c(rs_rejected, z)
    }
  }
  
  return(list(rs, rs_rejected))
}

ars_results = acceptance_rejection_sampling(10000)

```

The histogram of the drawn samples can be seen in the following figure:

```{r, echo = FALSE}

# For accessing them outside of the function if needed for e.g. plotting
M = 4
lambda = 1

df = as.data.frame(ars_results[[1]])
names(df) = "rs"

ggplot(df) +
  geom_histogram(aes(x = rs, y=..density..),
  color = "black", fill = "#dedede", bins = 100) +
  ggtitle("Gamma(2, 2) sampled from EXP(1)") +
  theme_minimal()

```

The expected rejection rate is given by $1 - \frac{1}{M}$ and here given by ``r 1 - 1/M``.

The observed rejection rate is given by $\frac{\text{rejected}}{\text{accepted} + \text{rejected}}$ and here given by ``r length(ars_results[[2]]) / (length(ars_results[[1]])+length(ars_results[[2]]))``.

```{r, echo = FALSE}

sequence = seq(from = 0, to = 6, by = 0.01)
dgamma_samples = sapply(X = sequence, FUN = dgamma, shape = 2, rate = 2)
dexp_samples = sapply(X = sequence, FUN = dexp, rate = 1)
df = data.frame(dgamma_samples, dexp_samples)

df$scaled_envelop = M * df$dexp_samples

ggplot(df) +
  geom_line(aes(x = sequence, y = dgamma_samples,
  colour = "Gamma Distribution (PDF)")) +
  geom_line(aes(x = sequence, y = dexp_samples,
  colour = "Exponential Distribution (PDF)")) +
  geom_line(aes(x = sequence, y = scaled_envelop,
  colour = "Envelope of Exponential Distribution (PDF)")) +
  labs(title = "Envelope", y = "Density",
  x = "X", color = "Legend") +
  scale_color_manual(values = c("#17202A", "#C70039", "#581845")) +
  theme_minimal()

ggplot(df) +
  geom_ribbon(aes(x = sequence, ymin = df$dgamma_samples, ymax = df$scaled_envelop),
            alpha = 0.8, fill = "#C70039", color = "#C70039") +
  geom_ribbon(aes(x = sequence, ymin = 0, ymax = df$dgamma_samples),
  alpha = 0.8, fill = "#DAF7A6", color = "#DAF7A6") +
  labs(title = "Acceptance and Rejection Regions", y = "Density",
  x = "X", color = "Legend") +
  scale_color_manual(values = c("#17202A", "#C70039", "#581845")) +
  theme_minimal()

```

**Question:** Compare (graphically and using relevant statistics) your simulated samples with the true Gamma distributions. Provide appropriate plots and comments.

**Answer:** We can see that the proposal envolops the target distribution but has a large rejection are. That's why we reject ``r length(ars_results[[2]]) / (length(ars_results[[1]])+length(ars_results[[2]]))`` which is given by $\frac{\text{rejected}}{\text{accepted} + \text{rejected}}$.

If we compare the real `Gamma(2, 2)` with the histrogram of our samples, they look almost identical-

*In the exam a plot of a histrogram of the real `Gamma(2, 2)` should be shown as well. Also different parameters should be used.*

## Question 1.3 (3 points)

The sampling function is given by:

$$d(x, \alpha=2, \beta=2) = 4xe^{-2x}$$

Note that $\text{Gamma}(\alpha) = (\alpha-1)!$

We then identify:

$$g(x) = \frac{1}{4}x^3$$
So we simply put our drawn samples into $g(x)$ and calculate the mean.

```{r}

################################################################################
# Assignment 1.3
################################################################################

g = function(x) return(1/4 * x^3)

mean(g(ars_results[[1]]))

```

# Assignment 2

```{r}

################################################################################
# Assignment 2
################################################################################

f = function(x) {
  return(-x * sin(10 * pi * x) + 1) 
}
```

The function to analyse looks like this.

```{r, echo = FALSE}
sequence = seq(from = -1, to = 2, by = 0.001)
f.sequence = f(sequence)

df = data.frame(sequence, f.sequence)

ggplot(df) + geom_line(aes(x = sequence, y = f.sequence), color = "#C70039") + 
  labs(title = "f(x)", y = "f(x)", x = "x") + theme_minimal()
```

## Question 2.1 (2 points)

The helper functions look like this.

```{r}

################################################################################
# Assignment 2.1
################################################################################

to_base_10 = function(v) {
  return(Reduce(function(s,r) {s*2+r}, v))
}

transform_to_interval = function(u, a = -1, b = 2, m = 15) {
  return(a + u * ((b - a)/(2^m - 1)))
}

chrom_to_x = function(chromosome) {
  return(transform_to_interval(to_base_10(chromosome)))
}

chrom_to_y = function(chromosome) {
  return(f(transform_to_interval(to_base_10(chromosome))))
}

```

## Question 2.2 (3 points)

```{r}

################################################################################
# Assignment 2.2
################################################################################

tournament_selection = function(population) {
  
  # Select fighting partners / groups
  fighters = sample(1:nrow(population), 4)
  
  # Get their values
  fighter_A = population[fighters[1],]
  fighter_B = population[fighters[2],]
  fighter_C = population[fighters[3],]
  fighter_D = population[fighters[4],]
  
  # Let them fight, group A
  if (chrom_to_y(fighter_A[2:length(fighter_A)]) <
      chrom_to_y(fighter_A[2:length(fighter_A)])) {
    winner_group_A = fighter_A
    looser_group_A = fighter_B
  }
  else {
    winner_group_A = fighter_B
    looser_group_A = fighter_A
  }
  
  # Let them fight, group B
  if (chrom_to_y(fighter_A[2:length(fighter_C)]) <
      chrom_to_y(fighter_A[2:length(fighter_D)])) {
    winner_group_B = fighter_C
    looser_group_B = fighter_D
  }
  else {
    winner_group_B = fighter_D
    looser_group_B = fighter_C
  }
  
  # Return them, first two are winners, last two are looser
  results = data.frame()
  results = rbind(results, winner_group_A)
  results = rbind(results, winner_group_B)
  results = rbind(results, looser_group_A)
  results = rbind(results, looser_group_B)
  
  return(results)
}

```

**Question:** Sometimes one varies this tournament selection and the best individual is chosen with a certain
probability lesser than 1. Can you provide a motivation for this?

**Answer:** If we have some knowledge about the function, that it's mostly monotonic, it might sense to put more emphasis on the best individial. The tournament selection might work better if a lot of individuals get stuck, like here, in local minima. Thus in this case the best individial (with a probability lesser than 1) might work better.

## Question 2.3 (5 points)

```{r}

################################################################################
# Assignment 2.3
################################################################################

# Generate a population of size n with m digits as genes
generate_population = function(n, m = 15) {
  
  population = data.frame()
  
   for (i in 1:n) {
     individual = c(i, ifelse(round(rnorm(m, mean = 0, sd = 1)) > 0, 1, 0))
     population = rbind(population, individual)
   }
  
  colnames(population) = c("index", as.character(seq(from = 1, to = m, by = 1)))
  return(population)
}

# Does a crossover where the children take one half of each parent
crossover = function(chrom_A, chrom_B) {
  chrom_A = unlist(chrom_A)
  chrom_B = unlist(chrom_B)
  
  cut = round(length(chrom_A)/2)
  
  child_A = c(chrom_A[2:cut], chrom_B[(cut+1):length(chrom_B)])
  child_B = c(chrom_B[2:cut], chrom_A[(cut+1):length(chrom_B)])
  
  return(list(child_A, child_B))
}

# Mutates a single bit based on prob
mutate_with_prob = function(x, prob) {
  if (runif(n = 1) < prob) {
    return(ifelse(x == 0, 1, 0))
  }
  else {
    return(x)
  }
}

# Mutates on average prob genes, each gene has a prob of prob/length to mutate
mutate = function(chrom, prob = 0.05) {
  chrom = unlist(chrom)
  # To get an average of 0.05 bits mutated
  digit_prob = prob / length(chrom)
  chrom[2:length(chrom)] = sapply(chrom[2:length(chrom)], mutate_with_prob, prob)
  return(chrom)
}

```

```{r}

# Helper function to get the best individial from a population
get_best_individual = function(population) {
  index_best = which.min(apply(population[,2:ncol(population)], 1, chrom_to_y))
  return(population[index_best,])
}

# Use all pre defined methods to actualy implement the genetic algorithm
genetic_algorithm = function(population_size = 55, mutprob = 0.05, runs = 100) {
  
  # Generate population
  population = generate_population(population_size)
  
  best_individual = get_best_individual(population)
  
  best_individual_iteration = 0
  
  for (i in 1:runs) {
    
    # Selection
    fighters = tournament_selection(population)
    
    # Create children of winners
    children = crossover(fighters[1,], fighters[2,])
    
    # Mutate the new individuals
    children[[1]] = mutate(children[1], prob = mutprob)
    children[[2]] = mutate(children[2], prob = mutprob)
    
    # Replace the loosers with the new winners
    population[fighters[3,1], 2:ncol(population)] = children[[1]]
    population[fighters[4,1], 2:ncol(population)] = children[[2]]
    
    # Save the overall best individual
    current_best = get_best_individual(population)
    if (chrom_to_y(current_best[2:length(current_best)]) <
        chrom_to_y(best_individual[2:length(best_individual)])) {
      best_individual = current_best
      best_individual_iteration = i
    }
  }
  
  return(list(best = best_individual, population = population,
              iteration = best_individual_iteration))
}

```

The example call for `mutprob = 0.0077` looks like this.

```{r}

results0077 = genetic_algorithm(population_size = 55, mutprob = 0.0077, runs = 100)
print(results0077$best)
print(results0077$iteration)

```

```{r, echo = FALSE}

X = apply(results0077$population[,2:ncol(results0077$population)], 1, chrom_to_x)
Y = f(X)

X_best = chrom_to_x(results0077$best[2:length(results0077$best)])
Y_best = f(X_best)

population = data.frame(X, Y)
best = data.frame(X_best, Y_best)

ggplot(df) +
  geom_line(aes(x = sequence, y = f.sequence), color = "#C70039") +
  geom_point(aes(x = population$X, y = population$Y),
             data = population, color = "black",fill = "#FFC300", shape = 21,
             size = 2, stroke = 1) + 
  geom_point(aes(x = best$X, y = best$Y), data = best, color = "black",
             fill = "#7BA9FF", shape = 21, size = 2, stroke = 1) +
  labs(title = "mutprob = 0.0077", y = "f(x)", x = "x") +
  theme_minimal()
```

The example call for `mutprob = 0.5` looks like this.

```{r}

results05 = genetic_algorithm(population_size = 55, mutprob = 0.5, runs = 100)
print(results05$best)
print(results05$iteration)

```

```{r, echo = FALSE}

X = apply(results05$population[,2:ncol(results05$population)], 1, chrom_to_x)
Y = f(X)

X_best = chrom_to_x(results05$best[2:length(results05$best)])
Y_best = f(X_best)

population = data.frame(X, Y)
best = data.frame(X_best, Y_best)

ggplot(df) +
  geom_line(aes(x = sequence, y = f.sequence), color = "#C70039") +
  geom_point(aes(x = population$X, y = population$Y),
             data = population, color = "black",fill = "#FFC300", shape = 21,
             size = 2, stroke = 1) + 
  geom_point(aes(x = best$X, y = best$Y), data = best, color = "black",
             fill = "#7BA9FF", shape = 21, size = 2, stroke = 1) +
  labs(title = "mutprob = 0.5", y = "f(x)", x = "x") +
  theme_minimal()

```

**Question:** At which generation was the best value found?

**Answer:** The best value for `mutprob = 0.077` was found in iteration ``r results0077$iteration`` and the best value for `mutprob = 0.5` was found in iteration ``r results05$iteration``.

**Question:** Was the minimum found?

**Answer:** For `mutprob = 0.077` no, for `mutprob = 0.5` yes. If we count in the error the encoding does, then `mutprob = 0.5` also did not find the minimum, but it found (probably) the best one the encoding of 15 bits could do.

**Question:** Can you explain the observed behaviour, especially when taking into account the mutation probability?

**Answer:** The mutation probability increases the randomness, which means how the space is being explored. A really high mutation makes the discovery mostly random, while a small one relies more on the characteristics of the parents. Here the function has a lot of *traps* which means relying on the parents is misleading. This means a higher mutation probability suits better for the problem we have here, which could change for other functions. A good way would be having a high mutation rate in the beginning of the algorithm ans slowly dicreasing on towards the end of the iterations, thus changed from global search to local search.

# Source Code

```{r, ref.label=knitr::all_labels(), echo = TRUE, eval = FALSE, results = 'show'}

```


